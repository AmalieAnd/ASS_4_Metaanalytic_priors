---
title: "Assignment 4 - Applying meta-analytic priors"
author: "Amalie Andersen"
output: html_document
---

```{r setup, include=FALSE}
setwd("~/Library/Mobile Documents/com~apple~CloudDocs/4. Aarhus Universitet/4. Semester/1. Computational Modelling/RFOLDER/ASS4_Metaanalytic priors/ASS4")

#Packages
pacman::p_load(readxl, coda, bayesplot, gridExtra, tidyverse, brms, metafor, lme4, ggplot2)

meta <- read_xlsx("Assignment4MetaData.xlsx")
pitch <- read_xlsx("Assignment4PitchDatav2.xlsx")
```

                                                          ### Assignment 4 ###

In this assignment we do the following:
- we reproduce the meta-analysis of pitch SD from last semester in a Bayesian framework
- we reproduce the pitch SD in schizophrenia analysis from last semester using both a conservative and a meta-analytic prior
- we assess the difference in model quality and estimates using the two priors.

The questions you need to answer are: 
- What are the consequences of using a meta-analytic prior? 
-Evaluate the models with conservative and meta-analytic priors. 
- Discuss the effects on estimates. 
- Discuss the effects on model quality. 
- Discuss the role that meta-analytic priors should have in scientific practice. Should we systematically use them? Do they have drawbacks? Should we use them to complement more conservative approaches? 
- How does the use of meta-analytic priors you suggest reflect the skeptical and cumulative nature of science?

### Step by step suggestions

#Step 1: Reproduce the meta-analysis of pitch sd from previous studies of voice in schizophrenia
- the data is available as Assignment4MetaData.xlsx
- Effect size (cohen's d), sd and variance are already calculated (you're welcome!)
- Since we're only interested in getting a meta-analytic effect size, let's take a shortcut and use bromance magic (brms): https://vuorre.netlify.com/post/2016/09/29/meta-analysis-is-a-special-case-of-bayesian-multilevel-modeling/

```{r plotting}
meta$MeanES <- as.numeric(meta$MeanES)
meta$Authors <- as.factor(meta$Authors)
meta$SdES <- as.numeric(meta$SdES)
meta$StudyID <- as.factor(meta$StudyID)

library(ggplot2)
ggplot(meta, aes(x=MeanES, y=StudyRef)) +
  geom_segment(aes(x = MeanES-SdES*2, xend = MeanES+SdES*2, y=StudyRef, yend=StudyRef)) +
  geom_point()
```

```{r meta analysis model}
meta_mod <- brm( 
  MeanES | se(VarianceES) ~ 1 + (1 | StudyID), 
  prior = c(set_prior("normal(0, 2)", class = "sd"),
            set_prior("normal(0, 2)", class = "Intercept")),
  iter = 10000,
  data = meta, 
  cores = 4
  )

meta_mod
#Population-Level Effects: 
#          Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
#Intercept    -0.62      0.29    -1.17    -0.01        500 1.00

# PRIORS ^^^^
#For each parameter, Eff.Sample is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence, Rhat = 1).

pairs(meta_mod, np = nuts_params(meta_mod))
plot(meta_mod)
traceplot(meta_mod)
show(meta_mod)
```

```{r trying out forest plot}
#forest plot  
install.packages("BiocManager") 
 
pacman::p_load(here, brms, brmstools)

forest(pitch_cons,
       show_data = TRUE,
       av_name = "Effect size")
```






# Step 2: Prepare the pitch SD data from last year
- the data is available as Assignment4PitchData.csv (thanks Celine)
- Also, let's standardize the data, so that they are compatible with our meta-analytic prior (Cohen's d is measured in SDs).
- Is there any structure in the dataset that we should account for with random effects? How would you implement that? Or, if you don't know how to do bayesian random effects, is there anything we would need to simplify in the dataset?

Yes, study. 

```{r standardising}
#scaling
pitch$pitchmean_s = scale(pitch$PitchMean) 
pitch$pitchSD_s = scale(pitch$PitchSD) 
pitch$pitchmedian_s = scale(pitch$PitchMedian)
pitch$pitchrange_s = scale(pitch$PitchRange)
pitch$pitchIQR_s = scale(pitch$PitchIQR)
pitch$pitchmad_s = scale(pitch$PitchMad)

#new df w/ scaled variables
pitch_s <- 
  select(pitch, ID_unique, diagnosis, studynr, trial, 13:18, PitchCV)
```




#Step 3: [CONSERVATIVE] Build a regression model predicting Pitch SD from Diagnosis.
- how is the outcome distributed? (likelihood function) 
- how are the parameters of the likelihood distribution distributed? Which predictors should they be conditioned on?
- use a skeptical/conservative prior for the effects of diagnosis. Remember you'll need to motivate it.
- Describe and plot the estimates. Evaluate model quality
```{r trial cons pitch model}
# pitch model w/ priors from meta model above
get_prior(pitchSD_s ~ 1 + diagnosis + (1 | studynr), data = pitch_s, family = gaussian())

pitch_cons <- brm(
  pitchSD_s ~ 1 + diagnosis + (1 | studynr), 
  prior = c(set_prior("normal(0, 0.1)", class = "Intercept"), 
            set_prior("normal(0, 0.1)", class = "b"), 
            set_prior("cauchy(0, 1)", class = "sd"), 
            set_prior("cauchy(0, 1)", class = "sigma")),
  data = pitch_s
)

#calling results
pitch_cons
#checking divergents
pairs(pitch_cons, np = nuts_params(pitch_cons))
#plot
plot(pitch_cons)
#traceplots
post <- posterior_samples(pitch_cons, add_chain = T)
mcmc_trace(post[, c(1:7,9)],  # we need to include column 7 because it contains the chain info 
           facet_args = list(ncol = 3), 
           size = .15) +
  labs(title = "My custom trace plots") + 
  scale_color_discrete() + 
  theme_light() +
  theme(legend.position = c(.95, .2))

#ppcheck
pp_check(pitch_cons)
```

```{r final_updated_cons_model}

pitch_cons_2 <- brm(
  pitchSD_s ~ 1 + diagnosis + (1 | studynr) + (1 | ID_unique) + (1 | trial), 
  prior = c(set_prior("normal(0, 0.1)", class = "Intercept"), 
            set_prior("normal(0, 0.2)", class = "b"),
            set_prior("cauchy(0, 0.1)", class = "sd", coef = "Intercept", group = "studynr"),    # random effect: study
            set_prior("cauchy(0, 0.1)", class = "sd", coef = "Intercept", group = "ID_unique"),  # random effect: ID
            set_prior("cauchy(0, 0.1)", class = "sd", coef = "Intercept", group = "trial"),      # random effect: trial
            set_prior("cauchy(0, 1)", class = "sigma")),
  iter = 10000,
  cores = 4,
  data = pitch_s
)

#calling results
pitch_cons_2
#checking divergents
pairs(pitch_cons_2, np = nuts_params(pitch_cons_2))
#plot
plot(pitch_cons_2)
#traceplots
post2 <- posterior_samples(pitch_cons_2, add_chain = T)
mcmc_trace(post2[, c(1:7,9)],  # we need to include column 7 because it contains the chain info 
           facet_args = list(ncol = 3), 
           size = .15) +
  labs(title = "My custom trace plots") + 
  scale_color_discrete() + 
  theme_light() +
  theme(legend.position = c(.95, .2))

#marginal effect
brms::marginal_effects(pitch_cons_2)

# PEEEPEEECHECK
pp_check(pitch_cons_2)

```

```{r density plot cons model}
f <-   
  fitted(pitch_cons_2) %>%
  as_tibble() %>%
  # tack the pitch_s data onto the fitted() results
  bind_cols(pitch_s)

 
# SCHIZOPLOT
pred.plot1 <- f %>%
  filter(diagnosis == 1) %>%
  ggplot(aes(x = Estimate)) +
  #stat_function(fun = dnorm, args = list(mean = 0, sd = 0.1), linetype = 2) +  
  geom_density(aes(x = pitchSD_s, color = "transparent", fill = "red", alpha = 1/2)) + geom_density(color = "transparent", fill = "dodgerblue3", alpha = 1/2) +
   
  scale_x_continuous(limits=c(-3,3)) + 
  
  labs(title = "Estimated data versus actual data (Diagnosis 1)",
       y     = "density") + theme(legend.position = "none")


#TD PLOT
pred.plot2 <- f %>%
  filter(diagnosis == 0) %>%
  ggplot(aes(x = Estimate)) +
  #stat_function(fun = dnorm, args = list(mean = 0, sd = 0.1), linetype = 2) +  
  geom_density(aes(x = pitchSD_s, color = "transparent", fill = "red", alpha = 1/2)) +
  geom_density(color = "transparent", fill = "dodgerblue3", alpha = 1/2) +
   
  scale_x_continuous(limits=c(-3,3)) + 
  labs(title = "Estimated data versus actual data (Diagnosis 0)",
       y     = "density")+ theme(legend.position = "none")


grid.arrange(pred.plot1, pred.plot2)


```

```{r Checking the chain (hairy caterpillars)}
p_load(bayesplot)
post <- posterior_samples(pitch_cons_2, add_chain = T)

mcmc_trace(post[, c(1:7,9)],  # we need to include column 7 because it contains the chain info 
           facet_args = list(ncol = 3), 
           size = .15) +
  labs(title = "My custom trace plots") + scale_color_discrete() + theme_light()+
  theme(legend.position = c(.95, .2))

post1 <- posterior_samples(pitch_cons_2, add_chain = T)
mcmc_trace(post1[, c(1:6,172)],  # we need to include column 7 because it contains the chain info 
           facet_args = list(ncol = 2), 
           size = .15) +
  labs(title = "Our custom trace plots #caterpillar") + scale_color_discrete() + theme_light()
```

```{r inspecting the estimates}
pitch_s$diagnosis <- as.numeric(pitch_s$diagnosis)

p50 <- 
  ggplot(data =  pitch_s, 
         aes(x = diagnosis, y = pitchSD_s)) +
  geom_abline(intercept = post1[1:50, 1], 
              slope     = post1[1:50, 2],
              size = 1/3, alpha = .3) +
  geom_point(shape = 1, size = 2, color = "royalblue") +
  coord_cartesian(xlim = range(pitch_s$diagnosis),
                  ylim = range(pitch_s$pitchSD_s)) +
  labs(subtitle = "N = 100") +
  theme_bw() +
  theme(panel.grid = element_blank())
p50
```






#Step 4: [META] Now re-run the model with the meta-analytic prior
- Describe and plot the estimates. Evaluate model quality
```{r meta pitch model}
pitch_meta <- brm( 
  pitchSD_s ~ 1 + diagnosis + (1 | studynr) + (1 | ID_unique) + (1 | trial),
  prior = c(set_prior("normal(0, 0.1)", class = "Intercept"), 
            set_prior("normal(-0.61 , 0.29)", class = "b"),
            set_prior("cauchy(0, 0.1)", class = "sd", coef = "Intercept", group = "studynr"),    # random effect: study
            set_prior("cauchy(0, 0.1)", class = "sd", coef = "Intercept", group = "ID_unique"),  # random effect: ID
            set_prior("cauchy(0, 0.1)", class = "sd", coef = "Intercept", group = "trial"),      # random effect: trial
            set_prior("cauchy(0, 1)", class = "sigma")),
  iter = 10000,
  data = pitch_s
  )

pitch_meta

#check of sampling --> looking for a pattern of red crosses
pairs(pitch_meta, np = nuts_params(pitch_meta))
plot(pitch_meta)

#marginal effects w/o data
brms::marginal_effects(pitch_meta)
pitch_s$diagnosis <- as.factor(pitch_s$diagnosis)

#marg effects w data
plot(marginal_effects(pitch_meta))
```

```{r plot meta }
pred.plot.mm1 <- mm %>%
  filter(diagnosis == 1) %>%
  ggplot(aes(x = Estimate)) +
  #stat_function(fun = dnorm, args = list(mean = -0.61, sd = 0.28), linetype = 2) + 
  geom_density(aes(x = pitchSD_s, color = "transparent", fill = "red", alpha = 1/2)) +
  geom_density(color = "transparent", fill = "dodgerblue3", alpha = 1/2) +
  scale_x_continuous(limits=c(-3,3)) + 
  
  labs(title = "Estimated data versus actual data for meta prior model (Diagnosis 1)",
       y     = "density") + theme(legend.position = "none")

pred.plot.mm2 <- mm %>%
  filter(diagnosis == 0) %>%
  ggplot(aes(x = Estimate)) +
  #stat_function(fun = dnorm, args = list(mean = -0.61, sd = 0.28), linetype = 2) + 
  geom_density(aes(x = pitchSD_s, color = "transparent", fill = "red", alpha = 1/2)) +
  geom_density(color = "transparent", fill = "dodgerblue3", alpha = 1/2) +
  scale_x_continuous(limits=c(-3,3)) + 
  labs(title = "Estimated data versus actual data for meta prior model (Diagnosis 0)",
       y     = "density")+ theme(legend.position = "none")

grid.arrange(pred.plot.mm1, pred.plot.mm2)
```

```{r another meta oooone}
# now use `fitted()` to get the model-implied trajectories
pm <-  
  fitted(pitch_meta) %>%
  as_tibble() %>%
  # tack the `pitch_s` data onto the `fitted()` results
  bind_cols(pitch_s)

pm %>%
  ggplot(aes(x = diagnosis, y = pitchSD_s)) +
  geom_abline(intercept = fixef(pitch_meta)[1], 
              slope     = fixef(pitch_meta)[2]) +
  geom_point(shape = 1, size = 2, color = "royalblue") +
  theme_bw() +
  theme(panel.grid = element_blank())
```

```{r meta traceplots}
meta.post <- posterior_samples(pitch_meta, add_chain = T)
mcmc_trace(meta.post[, c(1:6,172)],  # we need to include column 7 because it contains the chain info 
           facet_args = list(ncol = 2), 
           size = .15) +
  labs(title = "Our custom trace plots #caterpillar") + 
  scale_color_discrete() + 
  theme_light()
```





#Step 5: Compare the models
- Plot priors and posteriors of the diagnosis effect in both models
- Compare posteriors between the two models
- Compare their relative distance from truth (WAIC)
- Discuss how they compare and whether any of them is best.

```{r density plot of models against each other}  
# now use fitted() to get the model-implied trajectories
 mm <-  fitted(pitch_meta) %>%
  as_tibble() %>%
  # tack the pitch_s data onto the fitted() results
  bind_cols(pitch_s)

# cons
plot.cons.final <- f %>% 
  ggplot(aes(x = Estimate)) +
  stat_function(fun = dnorm, args = list(mean = 0, sd = 0.2), linetype = 2) +  
  geom_density(aes(x = pitchSD_s, color = "transparent", fill = "red", alpha = 1/2)) + 
  geom_density(color = "transparent", fill = "dodgerblue3", alpha = 1/2) +
   
  scale_x_continuous(limits=c(-3,3)) + scale_y_continuous(limits=c(-0,2)) +
  
  labs(title = "Estimated data versus actual data for model (m =0, SD = 0.2)", y = "density") + theme(legend.position = "none")

#meta
plot.meta <- mm %>%
    ggplot(aes(x = Estimate)) +
  stat_function(fun = dnorm, args = list(mean = -0.61, sd = 0.29), linetype = 2) +  
  geom_density(aes(x = pitchSD_s, color = "transparent", fill = "red", alpha = 1/2)) +
  geom_density(color = "transparent", fill = "dodgerblue3", alpha = 1/2) +
   
  scale_x_continuous(limits=c(-3,3)) + scale_y_continuous(limits=c(-0,2)) +
  labs(title = "Estimated data versus actual data for meta model (m =-0.61, SD = 0.29)",
       y     = "density")+ theme(legend.position = "none")

grid.arrange(plot.cons.final, plot.meta)
```

```{r SKROT compare models}
 
pitch_meta <- add_criterion(pitch_meta, "waic")
pitch_cons_2 <- add_criterion(pitch_cons_2, "waic")
#comparing WAIC
comp_score <- loo_compare(pitch_meta, pitch_cons_2, criterion = "waic")
print(comp_score, simplify = F)
#comparing them 
waic(pitch_meta, pitch_cons_2) #the outcome of the meta-analysis does slightly better
```

```{r WAIC comparison } 
# compute and save the WAIC information for the next three models
pitch_cons_2 <- add_criterion(pitch_cons_2, "waic")
pitch_meta <- add_criterion(pitch_meta, "waic")

# compare the WAIC estimates
w <- loo_compare(pitch_cons_2, pitch_meta,
                 criterion = "waic")

print(w, simplify = F)

model_weights(pitch_cons_2, pitch_meta, 
              weights = "waic") %>% 
  round(digits = 2)

#pitch_cons_2   pitch_meta 
#        0.98         0.02 
```



#Step 6: Prepare a nice write up of the analysis and answer the questions at the top.
See hand-in



